{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd767d485d3fe36",
   "metadata": {},
   "source": [
    "# Predict Protected Features\n",
    "\n",
    "In this notebook, we try to derive protected characteristics directly from the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50f6a9fae815ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from src.eval import EmbeddingEvaluator, Pathology\n",
    "import pytorch_lightning as L\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "EMBEDDING_FILE = 'mimic_cfm.npy'\n",
    "#EMBEDDING_FILE = 'mimic_chess.npy'\n",
    "#EMBEDDING_FILE = 'mimic_densenet_mimic.npy'\n",
    "\n",
    "#EMBEDDING_FILE = 'chex_chess.npy'\n",
    "#EMBEDDING_FILE = 'chex_densenet_chex.npy'\n",
    "\n",
    "META_FILE = 'mimic_meta.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffcd65d779f4e81",
   "metadata": {},
   "source": [
    "## Load Metadata and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b8e775dd8055e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_mimic_meta_data, get_chexpert_meta_data\n",
    "\n",
    "if 'mimic' in EMBEDDING_FILE:\n",
    "    train_df, val_df, test_df = get_mimic_meta_data(os.path.join(DATA_DIR, META_FILE))\n",
    "else:\n",
    "    train_df, val_df, test_df = get_chexpert_meta_data(DATA_DIR)\n",
    "print(f'DATASET SIZES: TRAIN {len(train_df)} | VAL {len(val_df)} | TEST {len(test_df)}')\n",
    "\n",
    "\n",
    "emb = np.load(os.path.join(DATA_DIR, EMBEDDING_FILE))\n",
    "emb = np.nan_to_num(emb)\n",
    "train_emb = emb[train_df['idx']]\n",
    "test_emb = emb[test_df['idx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69931c207f423c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EmbeddingEvaluator(train_df, test_df, train_emb, test_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f567dcf4f1a99aa",
   "metadata": {},
   "source": [
    "## 1. Predict Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655fa211c3e8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from src.net import TensorDataset, ClassificationModule\n",
    "from torch import nn, Tensor\n",
    "from typing import Sequence\n",
    "import warnings\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from pytorch_lightning.utilities.warnings import PossibleUserWarning\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_age_regressor(\n",
    "    x_train: np.ndarray,\n",
    "    y_train: Sequence,\n",
    "    x_val: Tensor,\n",
    "    y_val: Sequence,\n",
    "    max_epochs: int = 10,\n",
    "    batch_size: int = 256,\n",
    "):\n",
    "    # Create PyTorch datasets and data loaders\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2 * batch_size)\n",
    "\n",
    "    # Initialize the PyTorch Lightning model\n",
    "    model = ClassificationModule(\n",
    "        model=nn.Linear(x_train.shape[1], 1),\n",
    "        loss_func=nn.MSELoss()\n",
    "    )\n",
    "\n",
    "    # Initialize the PyTorch Lightning Trainer\n",
    "    warnings.filterwarnings('ignore', category=PossibleUserWarning)\n",
    "    trainer = L.Trainer(\n",
    "        logger=CSVLogger('lightning_logs'),\n",
    "        max_epochs=max_epochs,\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    # Train the model\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    # Remove shuffle for train predictions\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    res = {}\n",
    "    with torch.no_grad():\n",
    "        for loader, name in [(train_loader, 'train'), (val_loader, 'val')]:\n",
    "            y_pred_list = []\n",
    "            y_true_list = []\n",
    "            for x_batch, y_batch in loader:\n",
    "                y_pred = model(x_batch)\n",
    "                y_pred_list.extend(y_pred.detach().numpy() * 100)\n",
    "                y_true_list.extend(y_batch.numpy() * 100)\n",
    "\n",
    "            res[name] = y_pred_list\n",
    "            \n",
    "            \n",
    "\n",
    "            # Calculate Metrics using scikit-learn\n",
    "            mae = mean_absolute_error(y_true_list, y_pred_list)\n",
    "            r2 = r2_score(y_true_list, y_pred_list)\n",
    "            #print(f'{name} MAE: {mae:.4f} | R2: {r2:.4f}')\n",
    "            res[name] = (mae, r2)\n",
    "            \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f874aaabc2aab82",
   "metadata": {},
   "source": [
    "### Retrieve from Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5c0e989ca207",
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(1337424242)\n",
    "\n",
    "results = []\n",
    "for i in tqdm(range(10)):\n",
    "    r = train_age_regressor(\n",
    "        evaluator.train_emb,\n",
    "        train_df['age'].tolist(),\n",
    "        evaluator.test_emb,\n",
    "        test_df['age'].tolist(),\n",
    "    )\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897a375bcd3ec1e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_tuples = [e['val'] for e in results]\n",
    "maes, r2s = list(zip(*test_tuples))\n",
    "\n",
    "msg = ('{:.3f} $\\pm$ {:.3f} & {:.3f} $\\pm$ {:.3f}'\n",
    "       .format(np.mean(maes), np.std(maes), np.mean(r2s), np.std(r2s)))\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90cc02dd855b86e",
   "metadata": {},
   "source": [
    "### Retrieve from Orthogonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48f86810ba5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(1337424242)\n",
    "\n",
    "results = []\n",
    "for i in tqdm(range(10)):\n",
    "    r = train_age_regressor(\n",
    "        evaluator.train_emb_ortho,\n",
    "        train_df['age'].tolist(),\n",
    "        evaluator.test_emb_ortho,\n",
    "        test_df['age'].tolist(),\n",
    "    )\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb050fe-bdca-443f-8553-45c838a4b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tuples = [e['val'] for e in results]\n",
    "maes, r2s = list(zip(*test_tuples))\n",
    "\n",
    "msg = ('{:.3f} $\\pm$ {:.3f} & {:.3f} $\\pm$ {:.3f}'\n",
    "       .format(np.mean(maes), np.std(maes), np.mean(r2s), np.std(r2s)))\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714fc2514bb907fa",
   "metadata": {},
   "source": [
    "## 2. Predict Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6234be8773b5375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import eval_predictions\n",
    "\n",
    "\n",
    "def train_sex_regressor(\n",
    "    x_train: np.ndarray,\n",
    "    y_train: Sequence,\n",
    "    x_val: Tensor,\n",
    "    y_val: Sequence,\n",
    "    max_epochs: int = 10,\n",
    "    batch_size: int = 256,\n",
    "):\n",
    "    # Create PyTorch datasets and data loaders\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2 * batch_size)\n",
    "\n",
    "    # Initialize the PyTorch Lightning model\n",
    "    model = ClassificationModule(\n",
    "        model=nn.Linear(x_train.shape[1], 1),\n",
    "        loss_func=nn.BCEWithLogitsLoss()\n",
    "    )\n",
    "\n",
    "    # Initialize the PyTorch Lightning Trainer\n",
    "    warnings.filterwarnings('ignore', category=PossibleUserWarning)\n",
    "    trainer = L.Trainer(\n",
    "        logger=CSVLogger('lightning_logs'),\n",
    "        max_epochs=max_epochs,\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "    # Train the model\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    # Remove shuffle for train predictions\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    res = {}\n",
    "    with torch.no_grad():\n",
    "        for loader, name in [(train_loader, 'train'), (val_loader, 'val')]:\n",
    "            y_pred_list = []\n",
    "            y_true_list = []\n",
    "            for x_batch, y_batch in loader:\n",
    "                y_pred = model(x_batch)\n",
    "                y_pred_list.extend(torch.sigmoid(y_pred).detach().numpy())\n",
    "                y_true_list.extend(y_batch.numpy())\n",
    "\n",
    "            # Calculate Metrics using scikit-learn\n",
    "            m = eval_predictions(np.asarray(y_true_list), np.asarray(y_pred_list))\n",
    "            res[name] = (m['AUC'], m['SENS'], m['SPEC'])\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c9a5380c840af",
   "metadata": {},
   "source": [
    "### Retrieve from Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104809df717ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(1337424242)\n",
    "\n",
    "results = []\n",
    "for i in tqdm(range(10)):\n",
    "    r = train_sex_regressor(\n",
    "    evaluator.train_emb,\n",
    "    np.where(train_df['sex'] == 'M', 1, 0),\n",
    "    evaluator.test_emb,\n",
    "    np.where(test_df['sex'] == 'M', 1, 0),\n",
    ")\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0552ede-79ce-4d26-b165-65212e5fbc94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_tuples = [e['val'] for e in results]\n",
    "aucs, sens, specs = list(zip(*test_tuples))\n",
    "\n",
    "msg = ('{:.3f} $\\pm$ {:.3f} & {:.3f} $\\pm$ {:.3f} & {:.3f} $\\pm$ {:.3f}'\n",
    "       .format(np.mean(aucs), np.std(aucs), np.mean(sens), np.std(sens), np.mean(specs), np.std(specs)))\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649bdf8a15126c6",
   "metadata": {},
   "source": [
    "### Retrieve from Orthogonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61b6c642f90b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(1337424242)\n",
    "\n",
    "results = []\n",
    "for i in tqdm(range(10)):\n",
    "    r = train_sex_regressor(\n",
    "    evaluator.train_emb_ortho,\n",
    "    np.where(train_df['sex'] == 'M', 1, 0),\n",
    "    evaluator.test_emb_ortho,\n",
    "    np.where(test_df['sex'] == 'M', 1, 0),\n",
    ")\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2d23f-c57e-4372-88f7-92e1a624b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tuples = [e['val'] for e in results]\n",
    "aucs, sens, specs = list(zip(*test_tuples))\n",
    "\n",
    "msg = ('{:.3f} $\\pm$ {:.3f} & {:.3f} $\\pm$ {:.3f} & {:.3f} $\\pm$ {:.3f}'\n",
    "       .format(np.mean(aucs), np.std(aucs), np.mean(sens), np.std(sens), np.mean(specs), np.std(specs)))\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb34a03f-e189-4bbc-b28f-e8eb2effba5f",
   "metadata": {},
   "source": [
    "## 3. Predict Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5980bdeb-9746-48df-979f-80aa07820e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def eval_predictions_multiclass(true: np.ndarray, pred: np.ndarray):\n",
    "    # Get the number of classes\n",
    "    num_classes = np.max(true) + 1\n",
    "    res = {i : {} for i in range(num_classes)}\n",
    "\n",
    "    pred_classes = np.argmax(pred, axis=1)\n",
    "    aucs = roc_auc_score(true, pred, multi_class='ovr', average=None)\n",
    "    \n",
    "\n",
    "    # Initialize a list to store specificity for each class\n",
    "    specificity_per_class = []\n",
    "    sensitivity_per_class = []\n",
    "\n",
    "    # Calculate specificity for each class\n",
    "    for class_label in range(num_classes):\n",
    "        class_pred = (pred_classes == class_label).astype(int)\n",
    "        class_true = (true == class_label).astype(int)\n",
    "\n",
    "        # Compute the confusion matrix for the current class\n",
    "        confusion = confusion_matrix(class_true, class_pred)\n",
    "\n",
    "        # Extract true negatives and false positives for the current class\n",
    "        tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "        # Compute specificity for the current class\n",
    "        class_specificity = tn / (tn + fp)\n",
    "        class_sensitivity = tp / (tp + fn)\n",
    "\n",
    "        # Append specificity to the list\n",
    "        specificity_per_class.append(class_specificity)\n",
    "        sensitivity_per_class.append(class_sensitivity)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        res[i]['AUC'] = aucs[i]\n",
    "        res[i]['SENS'] = sensitivity_per_class[i]\n",
    "        res[i]['SPEC'] = specificity_per_class[i]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b2c222751e2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_race_regressor(\n",
    "        x_train: np.ndarray,\n",
    "        y_train: Sequence,\n",
    "        x_val: Tensor,\n",
    "        y_val: Sequence,\n",
    "        max_epochs: int = 10,\n",
    "        batch_size: int = 256,\n",
    "):\n",
    "    # Create PyTorch datasets and data loaders\n",
    "    train_dataset = TensorDataset(x_train, y_train, label_dtype=torch.long)\n",
    "    val_dataset = TensorDataset(x_val, y_val, label_dtype=torch.long)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2 * batch_size)\n",
    "\n",
    "    # Initialize the PyTorch Lightning model\n",
    "    model = ClassificationModule(\n",
    "        model=nn.Linear(x_train.shape[1], 3),\n",
    "        loss_func=nn.CrossEntropyLoss()\n",
    "    )\n",
    "\n",
    "    # Initialize the PyTorch Lightning Trainer\n",
    "    warnings.filterwarnings('ignore', category=PossibleUserWarning)\n",
    "    trainer = L.Trainer(\n",
    "        logger=CSVLogger('lightning_logs'),\n",
    "        max_epochs=max_epochs,\n",
    "        enable_model_summary=False,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    # Remove shuffle for train predictions\n",
    "    res = {}\n",
    "    with torch.no_grad():\n",
    "        for loader, name in [(train_loader, 'train'), (val_loader, 'val')]:\n",
    "            y_pred_list = []\n",
    "            y_true_list = []\n",
    "            for x_batch, y_batch in loader:\n",
    "                y_pred = model(x_batch)\n",
    "                y_pred_list.extend(torch.softmax(y_pred, dim=1).cpu().detach().numpy())\n",
    "                y_true_list.extend(y_batch.cpu().numpy())\n",
    "                \n",
    "            # Calculate Metrics using scikit-learn\n",
    "            res[name] = eval_predictions_multiclass(np.asarray(y_true_list), np.stack(y_pred_list))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094dcb72-ac0d-4e31-8f4c-b479c84a2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "L.seed_everything(1337424242)\n",
    "\n",
    "enc_race_train, unique_classes = pd.factorize(train_df['race'], sort=True)\n",
    "print(unique_classes)\n",
    "\n",
    "enc_race_test, unique_classes = pd.factorize(test_df['race'], sort=True)\n",
    "print(unique_classes)\n",
    "\n",
    "results = []\n",
    "for i in tqdm(range(10)):\n",
    "    r = train_race_regressor(\n",
    "    evaluator.train_emb,\n",
    "    enc_race_train,\n",
    "    evaluator.test_emb,\n",
    "    enc_race_test,\n",
    ")\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Retrieve from Original"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee0e356f89992af7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac36415-5277-42d9-84ab-0998fc0a9712",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tuples = [e['val'] for e in results]\n",
    "\n",
    "for i, cls in enumerate(unique_classes):\n",
    "    print(cls, '----------------------')\n",
    "    metrics = [t[i] for t in test_tuples]\n",
    "    \n",
    "    aucs = [m['AUC'] for m in metrics]\n",
    "    sens = [m['SENS'] for m in metrics]\n",
    "    specs = [m['SPEC'] for m in metrics]\n",
    "    \n",
    "    msg = ('{:.3f} $\\pm$ {:.3f} & {:.3f} $\\pm$ {:.3f} & {:.3f} $\\pm$ {:.3f}'\n",
    "           .format(np.mean(aucs), np.std(aucs), np.mean(sens), np.std(sens), np.mean(specs), np.std(specs)))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec1418a5e3b3224",
   "metadata": {},
   "source": [
    "### Retrieve from Orthogonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3b957a47ff84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(1337424242)\n",
    "\n",
    "enc_race_train, unique_classes = pd.factorize(train_df['race'], sort=True)\n",
    "print(unique_classes)\n",
    "\n",
    "enc_race_test, unique_classes = pd.factorize(test_df['race'], sort=True)\n",
    "print(unique_classes)\n",
    "\n",
    "results = []\n",
    "for i in tqdm(range(10)):\n",
    "    r = train_race_regressor(\n",
    "    evaluator.train_emb_ortho,\n",
    "    enc_race_train,\n",
    "    evaluator.test_emb_ortho,\n",
    "    enc_race_test,\n",
    ")\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d9d48-5673-4cac-a194-01ff7bbeaad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tuples = [e['val'] for e in results]\n",
    "\n",
    "for i, cls in enumerate(unique_classes):\n",
    "    print(cls, '----------------------')\n",
    "    metrics = [t[i] for t in test_tuples]\n",
    "    \n",
    "    aucs = [m['AUC'] for m in metrics]\n",
    "    sens = [m['SENS'] for m in metrics]\n",
    "    specs = [m['SPEC'] for m in metrics]\n",
    "    \n",
    "    msg = ('{:.3f} $\\pm$ {:.3f} & {:.3f} $\\pm$ {:.3f} & {:.3f} $\\pm$ {:.3f}'\n",
    "           .format(np.mean(aucs), np.std(aucs), np.mean(sens), np.std(sens), np.mean(specs), np.std(specs)))\n",
    "    print(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
