{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "from src.eval import Disease\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "#EMBEDDING_FILE = 'mimic_cfm.npy'\n",
    "#EMBEDDING_FILE = 'mimic_chess.npy'\n",
    "EMBEDDING_FILE = 'mimic_densenet_mimic.npy'\n",
    "META_FILE = 'mimic_meta.csv'\n",
    "\n",
    "#EMBEDDING_FILE = 'chex_chess.npy'\n",
    "#EMBEDDING_FILE = 'chex_densenet_chex.npy'\n",
    "#META_FILE = 'chexpert_meta.csv'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T15:07:41.144835708Z",
     "start_time": "2023-10-05T15:07:41.095338024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET SIZES: TRAIN 181342 | VAL 1413 | TEST 3041\n"
     ]
    }
   ],
   "source": [
    "from src.utils import get_mimic_meta_data, get_chexpert_meta_data\n",
    "\n",
    "train_df, val_df, test_df = get_mimic_meta_data(os.path.join(DATA_DIR, META_FILE))\n",
    "#train_df, val_df, test_df = get_chexpert_meta_data(DATA_DIR)\n",
    "print(f'DATASET SIZES: TRAIN {len(train_df)} | VAL {len(val_df)} | TEST {len(test_df)}')\n",
    "\n",
    "emb = np.load(os.path.join(DATA_DIR, EMBEDDING_FILE))\n",
    "emb = np.nan_to_num(emb)\n",
    "train_emb = emb[train_df['idx']]\n",
    "test_emb = emb[test_df['idx']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T15:07:48.512006797Z",
     "start_time": "2023-10-05T15:07:41.136635401Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from src.eval import EmbeddingEvaluator\n",
    "\n",
    "evaluator = EmbeddingEvaluator(train_df, test_df, train_emb, test_emb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T15:07:51.595261549Z",
     "start_time": "2023-10-05T15:07:48.514447216Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3041\n",
      "WHITE 2235\n",
      "BLACK 676\n",
      "ASIAN 130\n",
      "MALE 1658\n",
      "FEMALE 1383\n"
     ]
    }
   ],
   "source": [
    "print(len(test_df))\n",
    "print('WHITE', len(test_df[test_df['race'] == 'WHITE']))\n",
    "print('BLACK', len(test_df[test_df['race'] == 'BLACK']))\n",
    "print('ASIAN', len(test_df[test_df['race'] == 'ASIAN']))\n",
    "print('MALE', len(test_df[test_df['sex'] == 'M']))\n",
    "print('FEMALE', len(test_df[test_df['sex'] == 'F']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T15:07:51.637901095Z",
     "start_time": "2023-10-05T15:07:51.597791149Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from src.utils import eval_predictions\n",
    "from src.classifier import get_classifier\n",
    "\n",
    "\n",
    "def get_classifier_metrics(\n",
    "        evaluator,\n",
    "        run_name,\n",
    "        response: Disease = Disease.PLEURAL_EFFUSION,\n",
    "        clf_name: str = 'nn', clf_args = None,\n",
    "        runs = 1,\n",
    ") -> dict:\n",
    "    \n",
    "    subsets = {\n",
    "        'WHITE': test_df['race'] == 'WHITE',\n",
    "        'BLACK': test_df['race'] == 'BLACK',\n",
    "        'ASIAN': test_df['race'] == 'ASIAN',\n",
    "        'MALE': test_df['sex'] == 'M',\n",
    "        'FEMALE': test_df['sex'] == 'F',\n",
    "    }\n",
    "    \n",
    "    res = {\n",
    "        'id': [],\n",
    "        'run': [],\n",
    "        'subgroup': [],\n",
    "        'ortho':  [],\n",
    "        'auc': [],\n",
    "    }\n",
    "    \n",
    "    evaluator.train_df['response'] = (evaluator.train_df[response.value] == 1).astype(int)\n",
    "    evaluator.test_df['response'] = (evaluator.test_df[response.value] == 1).astype(int)\n",
    "\n",
    "    # Choose which embedding is the target\n",
    "    train_emb = evaluator.train_emb\n",
    "    test_emb = evaluator.test_emb\n",
    "\n",
    "    for run_id in range(1, runs + 1):\n",
    "        print('RUN', run_id, '-----------------')\n",
    "        model = get_classifier(clf_name, clf_args)\n",
    "        model.fit(train_emb, evaluator.train_df['response'].tolist())\n",
    "    \n",
    "        evaluator.test_df['preds'] = model.predict_proba(test_emb)[:, 1]\n",
    "        \n",
    "        #print('NORMAL --------------------')\n",
    "        m = eval_predictions(evaluator.test_df['response'], evaluator.test_df['preds'], do_print=False)\n",
    "        auc_normal = m['AUC']\n",
    "        #print('ALL', auc_normal)\n",
    "        \n",
    "        res['id'].append(run_name)\n",
    "        res['run'].append(run_id)\n",
    "        res['subgroup'].append('ALL')\n",
    "        res['ortho'].append(0)\n",
    "        res['auc'].append(auc_normal)\n",
    "        \n",
    "        for k, v in subsets.items():\n",
    "            m = eval_predictions(\n",
    "                evaluator.test_df[v]['response'],\n",
    "                evaluator.test_df[v]['preds'],\n",
    "                do_print=False\n",
    "            )\n",
    "            #print(k, m['AUC'])\n",
    "            \n",
    "            res['id'].append(run_name)\n",
    "            res['run'].append(run_id)\n",
    "            res['subgroup'].append(k)\n",
    "            res['ortho'].append(0)\n",
    "            res['auc'].append(m['AUC'])\n",
    "    \n",
    "        # Choose which embedding is the target\n",
    "        train_emb = evaluator.train_emb_ortho \n",
    "        test_emb = evaluator.test_emb_ortho\n",
    "    \n",
    "        model = get_classifier(clf_name, clf_args)\n",
    "        model.fit(train_emb, evaluator.train_df['response'].tolist())\n",
    "        \n",
    "        evaluator.test_df['preds'] = model.predict_proba(test_emb)[:, 1]\n",
    "    \n",
    "        #print('ORTHO --------------------')\n",
    "        m = eval_predictions(evaluator.test_df['response'], evaluator.test_df['preds'], do_print=False)\n",
    "        auc_ortho = m['AUC']\n",
    "        #print('ALL', auc_ortho)\n",
    "        \n",
    "        res['id'].append(run_name)\n",
    "        res['run'].append(run_id)\n",
    "        res['subgroup'].append('ALL')\n",
    "        res['ortho'].append(1)\n",
    "        res['auc'].append(auc_ortho)\n",
    "        \n",
    "        for k, v in subsets.items():\n",
    "            m = eval_predictions(\n",
    "                evaluator.test_df[v]['response'],\n",
    "                evaluator.test_df[v]['preds'],\n",
    "                do_print=False\n",
    "            )\n",
    "            res['id'].append(run_name)\n",
    "            res['run'].append(run_id)\n",
    "            res['subgroup'].append(k)            \n",
    "            res['ortho'].append(1)\n",
    "            res['auc'].append(m['AUC'])\n",
    "            \n",
    "            #print(k, m['AUC'])\n",
    "            \n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-05T15:07:51.704826934Z",
     "start_time": "2023-10-05T15:07:51.653513231Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN 1 -----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN 2 -----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN 3 -----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN 4 -----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN 5 -----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "#seed_everything(1337424242)\n",
    "\n",
    "res = get_classifier_metrics(evaluator, run_name='MIMIC_CLF', runs=10, response=Disease.PLEURAL_EFFUSION, clf_args={'max_epochs': 10})"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-05T15:07:51.705415598Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(res)\n",
    "df.to_csv('subgroup.csv', mode='a', header=False)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-05T15:14:20.853278318Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
